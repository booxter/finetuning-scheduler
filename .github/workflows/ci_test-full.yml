name: Test full

# see: https://help.github.com/en/actions/reference/events-that-trigger-workflows
on:  # Trigger the workflow on push or pull request, but only for the main branch
  push:
    branches: [main, "release/*"]
  pull_request:
    branches: [main, "release/*"]
    types: [opened, reopened, ready_for_review, synchronize]

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}-${{ github.head_ref }}
  cancel-in-progress: ${{ ! (github.ref == 'refs/heads/main' || startsWith(github.ref, 'refs/heads/release/')) }}

jobs:

  cpu:
    runs-on: ${{ matrix.os }}
    if: github.event.pull_request.draft == false
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-20.04, windows-2019, macOS-10.15]
        python-version: ["3.7", "3.9"]  # minimum, maximum
        # tests will include oldest and newest tested patch versions of pytorch-lightning
        requires: ["oldest", "latest"]
        release: ["latest"]
        # exclude:
          # - {os: ubuntu-20.04, python-version: "3.9", requires: "oldest"}
          # - {os: windows-2019, requires: "oldest"}
          # - {os: macOS-10.15, python-version: "3.9", requires: "oldest"}
        # include:
        #   # adding when using a release candidate
        #   # - {os: ubuntu-20.04, python-version: "3.10", requires: "latest", release: "pre"}

    timeout-minutes: 40

    steps:
    - uses: actions/checkout@v2
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v2
      with:
        python-version: ${{ matrix.python-version }}

    - name: Reset caching
      run: python -c "import time; days = time.time() / 60 / 60 / 24; print(f'TIME_PERIOD=d{int(days / 2) * 2}')" >> $GITHUB_ENV

    - name: basic setup
      run: |
        pip --version
        pip install -q fire

    - name: Set min. dependencies
      if: matrix.requires == 'oldest'
      run: |
        python .actions/assistant.py replace_oldest_ver

    # Note: This uses an internal pip API and may not always work
    # https://github.com/actions/cache/blob/master/examples.md#multiple-oss-in-a-workflow
    - name: Get pip cache dir
      id: pip-cache
      run: echo "::set-output name=dir::$(pip cache dir)"

    - name: pip cache
      uses: actions/cache@v2
      with:
        path: ${{ steps.pip-cache.outputs.dir }}
        key: ${{ runner.os }}-pip-td${{ env.TIME_PERIOD }}-py${{ matrix.python-version }}-${{ matrix.release }}-${{ matrix.requires }}-${{ hashFiles('requirements/base.txt') }}-${{ hashFiles('requirements/extra.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-td${{ env.TIME_PERIOD }}-py${{ matrix.python-version }}-${{ matrix.release }}-${{ matrix.requires }}-

    - name: Install dependencies
      run: |
        # flag=$(python -c "print('--pre' if '${{matrix.release}}' == 'pre' else '')" 2>&1)
        pip install --requirement requirements/base.txt --upgrade $flag
        pip install --requirement requirements/examples.txt --upgrade
        pip install --requirement requirements/test.txt --upgrade
        pip list
      shell: bash

    # - name: Install dependencies
    #   run: |
    #     flag=$(python -c "print('--pre' if '${{matrix.release}}' == 'pre' else '')" 2>&1)
    #     url=$(python -c "print('test/cpu/torch_test.html' if '${{matrix.release}}' == 'pre' else 'cpu/torch_stable.html')" 2>&1)
    #     pip install --requirement requirements.txt --upgrade $flag --find-links "https://download.pytorch.org/whl/${url}"
    #     # adjust versions according installed Torch version
    #     python ./requirements/adjust-versions.py requirements/examples.txt
    #     pip install --requirement requirements/examples.txt --find-links https://download.pytorch.org/whl/cpu/torch_stable.html --upgrade
    #     pip install --requirement requirements/test.txt --upgrade
    #     pip list
    #   shell: bash

    - name: Cache datasets
      uses: actions/cache@v2
      with:
        path: Datasets
        key: pl-dataset

    - name: Tests
      run: |
        # NOTE: do not include coverage report here, see: https://github.com/nedbat/coveragepy/issues/1003
        coverage run --source finetuning_scheduler -m pytest finetuning_scheduler tests -v --durations=50 --junitxml=junit/test-results-${{ runner.os }}-py${{ matrix.python-version }}-${{ matrix.requires }}-${{ matrix.release }}.xml

    # - name: Examples
    #   run: |
    #     python -m pytest fts_examples -v --durations=3

    - name: Upload pytest results
      uses: actions/upload-artifact@v2
      with:
        name: pytest-results-${{ runner.os }}-${{ matrix.python-version }}-${{ matrix.requires }}-${{ matrix.release }}
        path: junit/test-results-${{ runner.os }}-${{ matrix.python-version }}-${{ matrix.requires }}-${{ matrix.release }}.xml
      if: failure()

    - name: Statistics
      if: success()
      run: |
        coverage report
        coverage xml
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v2
      with:
        file: coverage.xml
        flags: cpu,pytest,python${{ matrix.python-version }}
        name: CPU-coverage
        fail_ci_if_error: false
        verbose: true # optional (default = false)
